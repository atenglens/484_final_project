# COS 484: Natural Language Processing, Spring 2022 Princeton University
## Final Project: Model Adjustments for Improving Novel Slot Detection
### Authors: Victoria Graf, Ashley Teng, Brendan Wang

Abstract: Novel Slot Detection (NSD) is a modified version of slot filling introduced by (Wu
et al., 2021) that allows slot types not in the predefined set to be identified at test time. Wu et al. propose a basic framework for a novel slot detection model involving an embedder, encoder, and classifier used for this new tagging task. The original model contained a BERT embedder and BiLSTM encoder. In this work, we propose three modifications to this framework to study model behavior: (1) adjustments to dropout and patience, (2) replacing the BERT embedder with ELMo and the OpenAI transformer, and (3) replacing the BiLSTM encoder with GRU and self-attention encoders. Using F1 scores and ROSE metrics, we find that the hyperparameter changes did not improve the performance, and the ELMo and OpenAI models achieve lower performance than the BERT model. We observe that GRU and self-attention models can outperform the BiLSTM model on some datasets, and that self-attention encoders are a promising future direction for improving the NSD task.
